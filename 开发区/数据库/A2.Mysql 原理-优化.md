## Mysql 原理-优化

#### mysql 执行过程： 

客户端 —>连接器 —>缓存—>分析器 —>优化器—>执行器 —>引擎 —> 查询结果  
客户端 —>连接器 —>缓存—> 查询结果  

调优是在执行器执行之前的分析器，优化器阶段完成

#### 主从复制同步原理：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gurwuc4hfij60h307zaab02.jpg" alt="216B1176-D897-40A4-BED9-E0784E96CFE8" style="zoom:100%;" />

1.从库启动复制时，首先创建  I/O 线程连接主库，主库随后创建 Binlog 线程将主库上的改变记录到二进制日志中
2.从库通过  I/O 线程，将主库的 二进制日志文件 copy 到 从库的中继日志 Relay Log
3.从库上的 SQL线程 读取中继日志 Relay Log，重做 中继日志中的事件，将数据的改变更新到自己的数据库中

- **异步复制：**主库执行完提交的事务后，会立即将结果返给给客户端，并不关心从库是否已经接收并处理，如果主 crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。

- **全同步复制：**指当主库执行 完一个事务，所有的从库都执行该事务后，主库才返回给客户端。需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

- **半同步复制：**主库执行完客户端提交的事务后 不是立刻返回给客户端，而是等待 至少一个从库接收到并写到 relay log中才返回给客户端。半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。

  

#### MySQL 数据一致性：

1.半同步，从库 ack 确认机制
2.缓存， 先写缓存再入主库，读从时先读缓存

**读写分离**

主服务器：写 +  读 （实时性要求高） 
从服务器：读 

**读写 分离能提高性能的原因在于：** 
1.主从服务器负责各自的 读和写，极大程度 缓解了锁的争用

2.从服务器可以使用 MyISAM，提升 查询性能以及 节约系统开销

3.增加 冗余，提高可用性

读写分离常用代理方式来实现： 代理服务器 接收应用层传来的读写请求，然后决定转发到哪个服务器

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gurwumox9hj60x20q4gne02.jpg" alt="DD2CC108-950E-4E49-B982-E984E6AD8076" style="zoom:60%;" />

#### explain 分析 select 查询语句，参数：

select_type：常用的有 SIMPLE 简单查询，UNION 联合查询，SUBQUERY子查询等
Table：要查询的表
possible_keys：可选择的索引

key： 实际使用的索引
rows： 扫描的行数 
type：索引查询类型，经常用到的索引查询类型：
    **const：使用 主键或 唯一索引 进行查询的时候只有一行匹配  
    **ref： 使用 非唯一索引
    **range：使用 主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询
    **index： 和 all的区别是 只扫描索引树  1.查询字段是索引的一部分，覆盖索引;  2.使用主键进行排序  
    **all：扫描全表 
system：触发条件：表只有一行，这是一个 const type 的特殊情况



#### 查询优化：

1.只返回 必要的列，行： 最好 不要使用 SELECT * 语句； 使用  LIMIT 语句来限制返回的数据；只有一条数据 limit 1

2.多使用普通索引,  背景：写多读少，对唯一性要求不高，或业务代码来保证唯一性时
普通索引使用 change buffer ，可以把一些写操作缓存下来，在读取的时候进行，避免磁盘操作，提高效率

3.注意：String 字段，但DB 中是int ,用到隐式转换 cast(str) 函数转换，导致不走索引
碰到不走索引情况，可以考虑使用 force index ,强制走索引；

4.建立联合索引：出现频率较高，常在一起作为 where条件的字段，考虑建立联合索引，减少建立索引的数量；并借助索引下推减少回表；减少服务器端扫描的行数, 使用 索引来覆盖查询
对于业务中有一些不好的索引，考虑使用覆盖索引，最左匹配原则，来把设置错误的索引给覆盖掉

5.开启 MRR（mult-range Read）：此操作可以在 回表之前，进行一个排序，把原来一个随机操作变成一个顺序操作
原理：根据辅助索引的叶子结点，找到主键值的集合并存储到read_rnd_buffer中，在该buffer中对主键值进行排序，最后利用已经排序好的主键值的集合，去访问表中的数据，这样就由原来的 随机/O变成为 顺序I/O，降低查询过程中的I/O消耗。

##### 6.分解大连接查询：

将一个 大连接查询分解成 对每一个表进行一次单表查询，然后在 应用程序中进行关联，这样做的好处有：
1.让缓存更高效； 对于连接查询，如果一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用
2.分解成多个单表查询；这些单表查询的缓存结果 更可能被其它查询使用到，从而减少冗余记录的查询。
3.减少锁竞争；在应用层进行连接，更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。查询本身效率也可能会有所提升。



##### 7.分页查询优化：

1.控制返回的总页数；
2.对超过特定阈值的页数进行 SQL 改写，借助主键 id 的索引覆盖
SELECT a.* FROM USER a  INNER JOIN  (SELECT id  FROM USER WHERE age = 10 LIMIT 100000,10) b  ON a.id = b.id;  结果0.53s
需要对 where条件增加索引，id 因为是主键自带索引，select返回减少回表可以提升查询性能, 所以采用查询主键字段后进行关联大幅度提升了查询效率。
3.使用Redis 来保存lastMaxtId, 下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。

##### 8.很长的字段如何设置索引：

索引选取越长，占用磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。
1.短长度：把字段 hash为另外一个字段存起来，每次校验 hash就好了，hash的索引也不大，hash 后的数值要 区分度过高。
2.高区分：通过函数处理倒序，删减字符串减少字段长度，并增加区分度； 如：身份证区域开头，同区域人很多，REVERSE() 函数翻转一下，提高区分度。



#### MySQL 工作原理：

![EE963375-2D0A-44B3-A209-211FEFFB0A07](https://tva1.sinaimg.cn/large/008i3skNly1gurwvhdqzkj60j20eq76s02.jpg)

#### Buffer Pool 

MySQL 不会直接去修改磁盘的数据，因为这样做太慢了，MySQL 会先记录 redo log，再改内存 Buffer Pool ，等有空了再刷磁盘，如果内存 Buffer Pool里没有数据，就去磁盘 load ；Buffer Pool 是 一个以 页为元素的链表。
持久化： 宕机时，Buffer Pool 丢失数据，重做 redo log； 先 redo log, 再 buffer pool 
Buffer Pool 链表结构：基于 LRU， 和缓存一样，需要淘汰算法来管理数据；

​          <img src="https://tva1.sinaimg.cn/large/008i3skNly1gurwvnzevmj60ip0cuq4a02.jpg" alt="4EC434C3-08BC-41E3-A059-E31B470752DB" style="zoom:80%;" />

#### Change  buffer:

​		查询数据时，如果内存里没有对应页的数据，MySQL 会从磁盘里 load ，如果每次需要的 页 都不同（或不是相邻的页），那每次都要去 load，很慢。如果 MySQL 发现你要修改的页不在内存里，就把要对页的修改，先记到一个叫 Change Buffer 的地方，同时记录 redo log，然后再慢慢把数据 load 到内存，load 过来后再把 Change Buffer 里记录的修改，应用到内存 Buffer Pool中，此操作： merge； 把内存数据刷到磁盘操作： purge 

 	  Change Buffer 只在操作「二级索引」时才使用，原因是「聚簇索引」必须是「唯一」的，也就意味着每次插入/更新，都需要检查 是否已经有相同的字段存在，也就没有必要使用 Change Buffer ；另外「聚簇索引」操作的随机性比较小，通常在相邻的「页」进行操作，比如使用自增主键的「聚簇索引」，那么 insert 时就是递增有/序的，不像「二级索引」，访问非常随机。

​		MySQL 以16KB「页」 为 读取和写入单位，一个「页」里面有多行数据，写入数据时，MySQL 会先写 内存中的页，然后再刷新到磁盘中的页。假设在某一次从 内存刷新到磁盘的过程中，一个「页」刷了一半，突然操作系统或 MySQL 进程 崩了，此时内存里的 页数据被清除了，而磁盘里的页数据，刷了一半，处于一个中间状态，可以说是一个「不完整」，甚至是「坏掉的」的页。 
redo log 在 磁盘中的页数据是正常、没有损坏情况下，才能把磁盘里页数据 load 到内存，如果磁盘中的页数据已经损坏，是无法应用 redo Log 的。

#### **Doublewrite Buffer：**

在 刷数据到 磁盘之前，先把数据写到另外一个地方 DoubleWrite Buffer， 写完后再开始写磁盘；Doublewrite Buffer 是一个备份，当发生 crash时，就可以利用 它来 修复磁盘里的数据

1.刷数据之前宕机：内存—> 磁盘，重做 redo log 日志 
2.刷数据时宕机： 利用 Doublewrite Buffer 修复磁盘数据

​		要更新一个数据页时，如果数据页在 内存中就直接更新；但如果这个数据页还没有在内存中，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在 change buffer中，这样就不需要 从磁盘中读入这个数据页。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作，通过这种方式就能保证这个数据逻辑的正确性。
Change buffer 是可以持久化的数据，在内存中有拷贝，也会被写入到磁盘上，将change buffer中的操作应用到原数据页，得到最新结果的过程称为 merge。

#### Merge触发条件：

1.访问这个数据页
2.系统后台线程定期 merge
3.在数据库正常关闭（shutdown）的过程中，也会执行merge

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gurww1abkbj60l80ws75l02.jpg" alt="E84FCF6C-D50D-46D4-92A6-93B6B4CC1FD9" style="zoom:50%;" />

​		将 更新操作先记录在 change buffer，可以减少读磁盘，语句的执行速度会得到明显的提升, 数据读入 内存是需要占用 buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率

#### 使用 change buffer 的条件？

普通索引可以使用 change buffer ,唯一索引（主键，聚簇索引）的更新就不能使用 change buffer
唯一索引更新操作都要先判断这个操作 是否违反唯一性约束, 要判断表中是否存在这个数据，就必须要将数据页读入内存才能判断，都已经读入到内存，那直接更新内存会更快，就没必要使用change buffer

change buffer 是 buffer pool里的内存，不能无限增大；
change buffer大小可以通过参数 innodb_change_buffer_max_size来动态设置，设置为50 表示change buffer大小最多只能占用buffer pool的50%

#### change buffer 使用场景：

适合：写多读少业务，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好，业务模型常见：账单类,日志类的系统
不适合：读多写少（写入后马上会做查询 ）将更新先记录在change buffer，但由于马上要访问这个数据页，会立即触发merge过程，访问IO次数不会减少，反而增加 change buffer的维护代价

数据库进行 Merge 时，是真正进行 数据更新的时刻，而 change buffer 主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer 记录的变更越多（页面上要更新的数据越多），收益就越大

**flush 操作：** redo log 会找个时间去更新到磁盘，这个操作就是flush
脏页：在更新之前，当内存数据页跟磁盘数据页内容不一致的时候
干净页：内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致

#### flush 操作条件：

1. InnoDB的 redo log写满了
2. 系统内存不足，需要淘汰一些数据页，空出内存给别的数据页使用。 如果淘汰“脏页”，就要先将脏页写到磁盘。
3. MySQL认为系统 “空闲”的时候，只要有机会就刷一点 “脏页”
4. MySQL正常关闭，会把内存的脏页都flush到磁盘上，这样下次启动的时候，就可以直接从磁盘上读数据，启动速度会很快。


​            

#### **MySQL 中数据的存储：**

各个 数据页 组成一个 双向链表； 
每个 数据页中的记录又组成一个 单向链表
每个 数据页都会为存储的记录 生成页目录，一个数据页内： 主键查找，二分法快速定位 ； 其他非主键列查找，从最小记录开始一次遍历单链表



#### 数据库连接池设置：

如果你有 10000个并发用户，设置一个10000的连接池基本等于失了智, 即是100也太多了。你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。