## MySQL优化实践



#### 1.大数据量拆分：

```mysql
update coupons 
set status = 1 
where status= 0 and create_time >= '2020-10-01 00:00:00' and create_time <= '2020-10-07 23:59:59';
```

问题： 一个 SQL只能使用一个 cpu core去处理，如果 SQL很复杂或执行很慢，就会 阻塞后面的 SQL请求，造成活动连接数暴增，MySQL CPU 100%，相应的 接口Timeout，同时对于 主从复制架构，做了业务读写分离，更新500w数据需要5分钟，Master上执行了5分钟，binlog传到了slave也需要执行5分钟，那就是Slave延迟5分钟，在这期间会造成 业务脏数据，比如重复下单等。

1.先获取 where 条件中的 最小id  ，最大id，
2.然后 分批次去更新，每个批次 1000条，这样既能快速完成更新，又能保证 主从复制不会出现延迟

先获取要更新的 数据范围内的 最小id和最大id（表没有物理delete，所以id是连续的）

```mysql
select min(id) min_id, max(id) max_id from coupons 
where status=0 
and create_time >= '2020-10-01 00:00:00' and create_time <= '2020-10-07 23:59:59’; 

current_id = min_id;
for current_id < max_id do
    update coupons set status=1 
    where id>= current_id and id<= current_id + 1000;    //通过主键id更新1000条很快
commit;
current_id += 1000;
done
```

充分利用 辅助索引包含主键id的特性，先通过索引获取主键 id走覆盖索引扫描，不需要回表，然后再通过id去关联操作是高效的，同时根据 MySQL的特性 使用分而治之的思想既能高效完成操作，又能避免主从复制延迟产生的业务数据混乱。



#### 2.分解多表连接：

例如，使用 IN() 代替连接查询（in 等价于等值查询）可排序，让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效

```mysql
SELECT * FROM tag
    JOIN tag_post ON tag_post.tag_id= tag.id
    JOIN post ON tag_post.post_id= post.id
    WHERE tag.tag='mysql’;

SELECT * FROM tag WHERE tag='mysql';           --> tag_id = 1234
SELECT * FROM tag_post WHERE tag_id=1234;      —> (123,456,567,9098,8904)
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```



#### 3.MRR优化： 

**应用实例一：**（mysql优化器改变where 条件顺序—>匹配联合索引） 

```mysql
SELECT * FROM t WHERE key_part1>=1000 and key_part1<2000 AND key_part2=1000;
```

表 t 有 ( key_part1,  key_part2 ) 的联合索引 ，因此索引根据 key_part1,  key_part2 的位置关系进行排序。
没有MRR：SQL优化器会先将 key_part1>1000 and key_part2<2000 的数据查询出来，待取出的数据后，再根据key_part2的条件进行过滤。这会导致无用的数据被取出，如果有大量的数据是 key_part2 !=1000，则启用MRR优化会使性能有巨大的提升.
启用MRR优化：优化器会先 将查询条件进行拆分，然后在进行数据查询。优化器会将查询条件拆分为(1000,1000),(1001,1000),(1002,1000),…,(1999,1000)，然后在根据这些拆分出的条件，使用索引下推进行数据查询，避免回表。

**应用实例二：**
 在没有MRR之前,或没有开启 MRR特性时，MySQL 针对基于辅助索引的查询策略是这样的：

```mysql
select non_key_column 
from tb where key_column=x;
```

MySQL 执行查询的伪代码
第一步 先根据 where 条件中的 辅助索引，获取辅助索引与主键的集合，结果集为 rest

```mysql
select key_column, pk_column from tb 
where key_column=x order by key_column 
```

第二步 通过第一步获取的主键来获取 对应的值

```mysql
for each pk_column value in rest do:
select non_key_column from tb where pk_column=val
```

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guryagegrej60ko0im3zx02.jpg" alt="71AD8A06-C4D7-4035-A63F-E0978354FC50" width="450" height="350"/>

由于MySQL存储数据的方式： 辅助索引的存储顺序并非与主键的顺序一致，从图中可以看出,根据辅助索引获取的主键来访问表中的数据会导致随机的IO . 不同主键不在同一个page 里面时必然导致多次IO 和随机读。
  在使用 MRR优化特性的情况下，MySQL 针对基于辅助索引的查询策略是这样的：
第一步 先根据 where条件中的辅助索引获取辅助索引与主键的集合，结果集为rest

```mysql
 select key_column, pk_column from tb where key_column = x order by key_column 
```

第二步 将结果集rest 放在buffer里面(read_rnd_buffer_size 大小直到buffer满了)，然后对结果集 rest按照pk_column排序，得到结果集是rest_sort
第三步 利用已经排序过的结果集，访问表中的数据，此时是顺序IO.

```mysql
 select non_key_column fromtb where pk_column in ( rest_sort )
```

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guryaq9apaj60y80hkwge02.jpg" alt="863DB3B3-6049-45F0-B0DC-16D319E21722" width="650" height="350"/>

​		从图示MRR原理，MySQL 将根据 辅助索引获取的结果集根据主键进行排序，将乱序化为有序，可以用-主键顺序访问基表，将随机读转化为顺序读，多页数据记录可一次性读入或 根据此次的主键范围分次读入，以减少IO操作，提高查询效率。
MRR的使用与否，是由 MySQL中的开关控制，只要设置开启，它会自动在 read_rnd_buffer_size 缓冲区 内，对primaryKey进行排序。但这个开关并不是一直开着，因为对于 大多数的单条查询，重新在中间添加一步排序，是对性能的损失，没有必要。所以Mysql 中还有一个 mrr_cost_based 开关，如果设置关闭，则完全按照 mrr 开关来执行了；如果设为开启，MySQL的优化器会通过 CBO算法确定是否开启MRR特性（进行对 primaryKey的排序）
mrr={on|off}
mrr_cost_based={on|off}



#### 4.大数据量下分页查询 limit offset, batchSize :

```mysql
select  * from trade_info 
where status = 0 and 
create_time >= '2020-10-01 00:00:00' and create_time <= '2020-10-07 23:59:59’ 
order by id desc 
limit 102120, 20;
```

表 trade_info 上有索引 idx_status_create_time(status, create_time); 等价于索引（status, create_time,id)
对于典型的 分页 limit m, n来说，越往后翻页越慢( m越大会越慢);  因为要 定位 m位置需要扫描的数据越来越多，导致IO开销比较大。这里可以利用 辅助索引的覆盖扫描来进行优化，先获取id，这一步就是 索引覆盖扫描，不需要回表，然后通过 id 跟原表 trade_info进行关联
// 改写后的SQL如下：

```mysql
select * 
from trade_info a , 
   (select id from trade_info 
    where status = 0 
    and create_time >='2020-10-01 00:00:00' and create_time <='2020-10-07 23:59:59’ 
    order by id desc limit 102120, 20)  as b    -- 这一步走的是索引覆盖扫描，不需要回表
 where a.id = b.id;
```

**问题：** 分页查询时，MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，而且在取offset+N 行数据时，因为是select * ... 的操作，所以是需要回表的，查询到索引叶子节点数据，根据叶子节点上的主键值去聚簇索引上查询需要的全部字段值。
那当 offset 特别大的时候，此时使用 limit m,n 效率就非常的低下，因为回表了 M 行无用的数据，并且占用了大量的 buffer pool 缓存。

#### 解决方案:

1.控制返回的总页数；
2.对超过特定阈值的页数进行 SQL 改写
SELECT a.* FROM USER a  INNER JOIN  (SELECT id  FROM USER WHERE age = 10 LIMIT 100000,10) b  ON a.id = b.id;  结果0.53s
需要对 where条件增加索引，id 因为是主键自带索引，select返回减少回表可以提升查询性能, 所以采用查询主键字段后进行关联大幅度提升了查询效率。
3.使用Redis 来保存lastMaxtId, 下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。



#### 常见慢查询问题：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guryax8sv9j61860oan1002.jpg" alt="14B56083-7EBD-4768-AD40-E3C00DFA418D" width="850" height="500" />



1.确定主键，索引字段，将它们作为查询条件
2.数据量过大，使用 limit 做分页处理，  limit  起始id, 条数count 
3.当 limit 起始行数很大时， 查询效率会降低， 可以考虑使用自增 id 

```mysql
Select *. From table limit  150000 , 5000

优化： Select * from table where id>150000 and id<200000;  -- 速度会有提升
```

4.数据导入，可尝试批量导入数据 ；   性能：    Load  > insert. 
 load 只操作一次，之后数据 批量插入
 insert 每个数据操作一次，’就要遍历 一次字段索引