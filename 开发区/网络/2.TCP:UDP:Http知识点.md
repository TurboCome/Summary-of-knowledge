## TCP/UDP/Http

#### http 中的长，短链接：

​		在 HTTP/1.0中 默认短连接，客户端和 服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就 中断连接。当客户端浏览器访问某个Web页中包含有其他的 Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

​		从HTTP/1.1起，默认长连接，用以 保持连接特性。使用长连接的 HTTP协议，会在 响应头加入这行代码：Connection:keep-alive；
使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间 用于传输 HTTP数据的 TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，有一个保持时间，可以设定这个时间。实现长连接需要客户端和服务端都支持长连接。

HTTP 协议的长，短连接，实质上是 TCP协议的长，短连接。
**http 长连接：**设置 connection 为 keep-alive ；在 header 中有个超时时间，超过此时间就断开长连接
长连接： 多个 http 请求复用同一个 TCP ； 频繁通信 
短链接： 一个 http 用一个 TCP；  长时间不通信，创建，关闭都会浪费时间

长优点： 省去较多的 TCP建立和关闭操作，减少浪费，节约时间，对于 频繁请求资源的客户端较适合 
短优点： 管理起来简单，存在的连接都是有用的连接，不需要额外的控制手段 

​		像 Web 网站的 http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像 web网站有大量的客户端连接 用 短连接会省一些资源，如果用长连接，同时有成千上万的用户，每个 用户都占用一个连接的话，并发量很大，资源消耗很大； 而且每个用户无需频繁操作。



#### 浏览器中输入一个网址 url，执行过程：

1.应用层：浏览器看是否有缓存（浏览器，本地）; 没有则通过 DNS 解析，将 域名 转成其所对应的 服务器 ip地址，确定从浏览器到服务器的一条路径
2.传输层：将 http 会话通过 TCP 协议封装成数据包，在 源，目的端添加 对应的端口号, 来保证端到端的可靠传输
3.网络层：通过 IP 协议，查找 路由表，确定如何路由线路，到达服务器
4.数据链路层： 通过 邻居发现协议 ND， 查找到 给定 IP 地址的 mac 地址，发送 ARP 请求查找目的地址
5.物理层：将 ip 数据包转换成比特流，在物理链路上传输

#### Web 页面请求过程：

1.浏览器进行DNS域名解析，得到对应的IP地址
2.根据这个IP，找到对应的服务器，建立连接（三次握手）
3.建立TCP连接后发起 HTTP请求（一个完整的http请求报文）
4.服务器响应HTTP请求，浏览器 得到 html代码（服务器如何响应）
5.浏览器 解析 html代码，并请求 html代码中的资源（如js，css，图片等）
6.浏览器 对页面进行渲染呈现给用户
7.服务器关闭 TCP连接（四次挥手）#

#### DNS解析

1.首先会搜索浏览器自身的 DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）

2.如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存

3.如果还没有找到，那么尝试从 hosts文件里面去找

4.在前面三个过程都没获取到的情况下，浏览器会发起一个DNS的系统调用，向本地配置的首选DNS服务器（一般是电信运营商提供）发起域名解析请求（通过 UDP协议向 DNS的 53端口发起请求，这个请求是递归的，就是要求运营商的DNS服务器必须提供给我们该域名的IP地址）
DNS优化两个方面： DNS缓存, DNS负载均衡
参考：https://zhuanlan.zhihu.com/p/161560683



#### TCP 与 UDP 区别：

1.基于 TCP有连接； UDP 无连接；
2.TCP数据正确性，可靠传输，无差错，不丢失，不重复，且按序到达；
   UDP可能丢包，不可靠传输，UDP 尽最大努力交付，即不保   证可靠交付
   UDP没有拥塞控制，因此网络出现 拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
3.UDP 程序结构较简单，速度快，适合传输大数据； TCP 速度慢，适合小数据传输
4.TCP面向字节流;  UDP是面向报文的
5.每一条 TCP连接只能是点到点的;  UDP支持一对一，一对多，多对一和多对多的交互通信
6.TCP首部开销 20字节;  UDP的首部开销 8个字节
7.TCP通信 信道是 全双工的可靠信道，UDP则是 不可靠信道



#### 流量控制 ： 

**点对点  让发送速率不要过快**，使接收方来得及接收;  利用 滑动窗口机制就可以实施流量控制
**原理：**运用 TCP报文段中的 窗口大小字段来控制，发送方的发送窗口不能  > 接收方发回的窗口大小
滑动窗口协议是传输层进行流控的一种措施，接收方告知发送方自己可以接受缓冲区大小（此字段越大--网络吞吐量越高），从而控制发送方的发送速度，如果接收端缓冲区面临数据溢出，窗口大小值会被设置一个更小的值通知给发送端，从而控制数据发送量（发送端根据接收端指示，进行流量控制）

**拥塞控制：**整个网络解决 过多的 数据注入到网络,  导致网络崩溃,  超过负荷, 拥塞控制包含四个策略
防止过多的数据注入到网络中，导致网络中的 路由器或链路过载；发送方控制 拥塞窗口的原则是：只要网络 没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去； 但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

#### **拥塞控制四个策略：**

**1.慢开始：**发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2,4,8 …； 慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，慢开始结束。

**2.拥塞避免：**慢开始结束后 是 拥塞避免, 此时拥塞窗口 每个传输轮次 + 1,  直到 触发网络拥塞；如果出现超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

**3.快重传：**在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 
		快重传要求 接收方在 收到一个失序的报文段后 ，立即发出重复确认，而  不是等到自己发送数据时 捎带确认；发送方只要一连收到三个重复确认ACK， 就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
**4.快恢复：配合快重传使用**，在收到三个重复确认ACK后，这种情况下只是丢失个别报文段，不是网络拥塞。因此执行快恢复，设ssthresh = cwnd/2 ，cwnd = ssthresh，注意到此时直接进入 拥塞避免。 

注意：在采用快恢复算法时，慢开始算法只是在 TCP连接建立时和网络出现超时时才使用

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guru93o6d9j612w0gimzi02.jpg" alt="0043A64C-1752-4B59-805F-250ED799F749" width="750" height="300"  />

#### 流量控制与拥塞控制 区别：

**相同点：** 都会丢包；实现机制都是让发送方发的 慢一点，发的少一点； 提高网络性能
**不同点：**
1.丢包位置不同， 流量控制丢包位置是在接收端上；  拥塞控制丢包：在路由器上
2.作用对象不同： 流量控制对象是 接收方，防止发送方发的太快，来不及接受； 拥塞控制对象是 网络，防止发送方发的太快，造成网络拥塞，超过网络负荷
3.联系： 拥塞控制是 一个全局性的过程，涉及网络中的所有主机，所有路由器，考虑网络负荷；流量控制是局部的，发生在端和端之间，是点到点的控制。



#### TCP三次握手：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guru9fuobcj60nr0fddh202.jpg" alt="Image" width="650" height="400" />

客户端和 服务器建立的是可靠的   全双工连接：
客户端：确定，服务器是可以接受，发送数据
服务器：确定，客户端是可以接受，发送数据

**第一次握手：**建立连接时，客户端发送 syn包 (syn=j)到服务器，并进入 SYN_SEND状态，等待服务器确认；此时对于服务器而言，服务器知道自己的 “接收”能力正常，客户端的 “发送”能力正常。
**第二次握手：**服务器收到 syn包，确认客户 SYN（ack=j+1），同时自己也发送一个SYN包(syn=k)，即SYN+ACK包 ，此时服务器进入 SYN_RECV状态；
此时对于客户端而言，客户端知道自己的“发送”能力正常；客户端的“接收”能力正常； 知道服务器的“发送”、“接收”能力正常
此时对于服务器而言，服务器知道客户端“发送”能力正常，但客户端“接收”能力不确定，同时，服务器知道自己“接收”能力正常，但“发送”能力不确定 。
**第三次握手：**客户端收到服务器SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，发送完毕后客户端和服务器进入 ESTABLISHED状态，完成三次握手。
此时对于服务器而言，服务器就能确定自己的“发送”能力正常，客户端的“接收”能力正常。
通过这样的三次握手，双方都能确定自己和对方的收，发能力正常，客户端与 服务端建立起 可靠的双工的连接，开始传送数据。

​		TCP 协议为实现可靠传输， 通信双方需要判断自己已经发送的数据包是否都被接收方收到， 如果没收到， 就需要 重传。 为了实现这个需求，就涉及到 序号（sequence number） 和 确认号（acknowledgement number） 这2个概念 。
**序列号 seq：**TCP 连接中传送的数据流中每一个字节都编上一个序号，序号字段的值是 本报文段所发送的数据的第一个字节的序号。
**确认号 ack：**期望收到对方下一个报文段数据的第一个字节的序号。



#### 四次挥手：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guru9mrx5dj60ft0ap3za02.jpg" alt="C04AF208-878B-4928-A90D-ABB44B58C24C" width="650" height="400"  />

**第一次：**A 应用进程先向其 TCP发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。
**第二次：**B 收到连接释放报文段后即发出确认报文段，（ACK=1，确认号ack=u+1，序号seq=v），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。
A 收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。
此时客户端不再向服务器发送数据，服务器不再接受数据； 但服务器还会将没发送完的数据发给客户端，客户端可以继续接受服务器发来的数据。
**第三次：**当B没有要发的数据时，释放报文段(FIN=1，ACK=1，序号seq=w，确认号ack=u+1)，B进入LAST-ACK最后确认状态，等待A确认。
**第四次：**A收到B的连接释放报文段后，对此发出确认报文段(ACK=1，seq=u+1，ack=w+1)，A进入 TIME-WAIT（时间等待）状态。此时 TCP未释放掉，需要 经过时间 等待计时器设置的时间 2MSL后，A才进入CLOSED状态。



#### 为什么 A 在 TIME-WAIT状态等待 2MSL的时间？

MSL 最长报文段寿命 Maximum Segment Lifetime，MSL=2
**1.避免B 服务端无法 closed 关闭；**确保有足够时间让 服务器 收到 对方的 ACK 包，一来一去就是2MSL； TCP 可靠的，服务器在 2MSL 时间后没收到ACK 会超时重传 ；ACK 报文段可能丢失，使得处于LAST-ACK状态的B 收不到对已发送的 FIN+ACK报文段的确认，B 超时重传FIN+ACK报文段，而 A 能在 2MSL时间内收到这个重传的 FIN+ACK报文段，接着 A重传一次确认，重新启动 2MSL计时器，最后A和B都进入到CLOSED状态；若A在TIME-WAIT状态不等待一段时间，而是 发送完 ACK报文段后立即释放连接，则 无法收到 B重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则 B无法正常进入到CLOSED状态。

**2.避免 新旧连接混: 即 不会跟后面的 新连接混淆；**  防止“ 已失效的连接请求 报文段”出现在本连接中；A 在发送完最后一个 ACK报文段后，再经过 2MSL，可以使 本连接持续时间内所产生的所有报文段 都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。



#### 为什么连接时三次握手，关闭时四次握手？

当 Server 端收到 Client 端的 SYN连接请求报文后，可以直接 **发送SYN+ACK报文**。其中 ACK报文是用来应答的，SYN报文是用来同步的 
但是关闭连接时，当 Server端收到FIN报文时，可能不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉 Client端，你发的FIN报文我收到。只有等到我 Server端所有的报文都发送完，我才能发送FIN报文，因此不能一起发送,  故需要四步握手。



#### SYN泛洪（SYN flood）攻击：

​		如果大量的握手请求涌向TCP服务端，而它们只发出SYN报文而不以ACK响应结束握手，服务端就要为这每一个请求都维持约一分多钟的连接去等待ACK，也就形成所谓的“半连接”。维护这些半连接是需要消耗很多服务器的网络连接资源的。如果短时间内这些资源几乎都被半连接占满，那么正常的业务请求在这期间就得不到服务，处于等待状态。如果这些半连接的握手请求是恶意程序发出，并且持续不断，那么就会导致服务端较长时间内丧失服务功能——这就形成了DoS（Denial of Service拒绝服务）攻击。



#### Http的方法：

Get, post 是客户端和服务器端进行请求-响应的常用方法
**GET 请求： 获取资源**
1.可被 缓存
2.保留在 浏览器历史记录中
3.有长度限制；URL 的最大长度是 2048 个字符
4.可被 收藏为书签
5.数据在 URL 中对所有人都是可见的
6.传输的表单在 url中

**POST 请求： 传输实体主体**
1.不会被缓存
2.不会保留在浏览器历史记录中
3.没有对数据长度的限制
4.不能 被收藏为书签
5.数据不会显示在 URL 中
6.传输的表单在request请求的 body中

**HEAD： 获取报文首部**

和GET方法类似，但服务器在响应中 只返回首部，不返回实体的主体部分；允许客户端在未获取实际资源情况下，对资源首部进行检查
优点：
1.在 不获取资源的情况下 了解资源（比如：判断其类型）；
2.通过查看 响应的状态码，看看某个对象是否存在；
3.通过查看首部，测试资源是否被修改  

**PUT： 上传文件**
由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法



#### HTTP 和 HTTPs  区别：

HTTP 的请求过程：
1.TCP 建立连接后，客户端会发送报文给服务端；
2.服务端接收报文并作出响应；
3.客户端收到响应后解析给用户；
HTTP协议 不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信,非常不安全

HTTPS 在 HTTP 的基础上加入 SSL 层，HTTPS 的安全基础是 SSL，HTTPS 存在 不同于 HTTP 的默认端口和 一个加密/身份验证层(在HTTP与 TCP之间）这个系统提供了 身份验证与加密通讯方法;  它被广泛用于万维网上安全敏感的通讯，例如交易支付等方面。



#### HTTPS的请求过程：

1.客户端 发送请求到 服务端；
2.服务器返回 数字证书（公钥，明文数据，签名，服务器域名）
3.客户端 根据数字证书来验证服务器是不是自己要访问的（有效性），有效则随机生成对称加密的密钥X，并使用公钥加密密钥X，然后发送到服务端；
4.服务端使用 私钥解密，得到 对称密钥X ； 后续使用密钥 X 对报文加密传输

**数字证书：**验证访问的 服务器网站是有效的，合法的
**签名：** 验证 数字证书是有效的
CA 机构对数字证书中的 明文数据，做 hash ，然后使用 私钥加密得到 签名 S
浏览器收到 数字证书后，通过 公钥对签名 S 解密得到 T， 然后对 明文数据进行 hash 得到 T’ ；通过验证T==T’ 来保证数字证书没有被篡改
Hash 作用：证书信息一般较长，而 hash后得到固定长度的信息(比如用 md5算法hash后得到固定的 128位的值),这样加密，解密会快很多
**数字证书公钥：** 操作系统，浏览器本身会预装一些它们信任的根证书，其中会有 CA机构的根证书，这样就可以拿到它对应的 可信公钥，不是每次请求都经历一次密钥传输过程：服务器 会为每个浏览器维护一个 session ID，浏览器生成好 密钥X传给服务器，服务器把该 密钥X存到相应的 session ID，之后 浏览器每次请求都会携带 session ID，服务器根据 session ID 找到相应的密钥进行解密，加密操作。
		服务器端有个session ID 表，客户端第一次带着账户信息请求时，服务端查库，并产生一个 sessionID 返回给客户端，客户端之后请求时，会把 sessionID 放到cookie 中，携带cookie 请求，服务端通过校验sessionID，如果在sessionID表中，直接通过避免查库。

#### HTTPS 缺点：

1.https协议是 多次握手，导致页面 加载时间延长近50%;
2.https 连接 缓存不如HTTP高效，会 增加数据开销和功耗;
3.申请SSL 证书需要钱，功能越强大的证书费用越高; 
4.SSL涉及到的安全算法会 消耗 CPU 资源，对服务器资源消耗较大

#### http 和 https 区别：

1.https 是 http 协议的安全版本
2.http 协议的 数据传输是明文的，是不安全的;   https使用 SSL/TLS 非对称加密协议进行加密处理， 是安全的
3.http 和https 使用连接方式不同，默认端口不一样，http是80，https是443
4.https协议对传输的数据进行加密，内容传输上使用对称加密，证书验证上使用非对称加密

#### Https整体过程分为证书验证和数据传输阶段：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guruaqnpc6j60y40u0tcd02.jpg" alt="2BD4ED6C-0A4F-49AE-AD91-A0675CDBC23C" width="750" height="600"  />

​		非对称加密的 **加解密效率**是 非常低的，而 http 应用场景中通常 端与端之间存在大量的交互，非对称加密的效率是无法接受的。
在 https场景中只有 服务端保存私钥，一对公钥，私钥只能实现单向的加密和解密，所以https 中内容传输加密是 对称加密，证书验证是非对称加密。

#### 常见的状态码：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gurvv95xvsj61a60q0q8102.jpg" alt="image-20210924172152459" width="750" height="400"  />

301 永久重定向；  302 暂时重定向；  网站调整； 网页移到新地址； 扩展名改变



#### Cookie：

HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。
Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。
Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。

#### 用途：

* 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
* 个性化设置（如用户自定义设置、主题等）
* 浏览器行为跟踪（如跟踪分析用户行为等）



#### Session：

​		除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。
Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。
使用 Session 维护用户登录状态的过程如下：

* 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
* 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
* 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
* 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。
应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

#### Cookie 与 Session 选择

* Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
* Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
* 对于大型网站，如果用户所有信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有用户信息都存储到 Session 中。#



#### RPC  与 http  区别：

RPC ： 远程调用其他计算机服务，底层使用 TCP 传输协议； 指定数据传输格式，序列化方式 
相同点： 底层都是基于 socket 编程，使用 TCP 协议，实现远程调用，服务调用 服务
不同：
RPC ： 提供方，消费方 都使用 统一的RPC 框架（ dubbo）, 跨操作系统，同一编程语言内使用；  调用快，处理快，实现复杂
HTTP： 跨操作系统，跨编程语言； 通用性强， 实现简单



#### **区分 MSS 与 MTU：**

最大传输单元（Maximum Transmission Unit, MTU）， 最大报文段长度（Maximum Segment Size ，MSS）协议用来定义最大长度的
MTU 应用于 数据链接层，并无具体针对的协议。 MTU限制数据链接层上可以传输的数据包的大小，也因此限制了上层（网络层）的数据包大小。例如，如果已知 某局域网的 MTU为1500字节，则在网络层的因特网协议（ IP）里最大数据包大小为 1500字节（包含IP协议头）。
MSS 应用于 传输层的TCP协议，因为 MSS应用的协议在数据链接层的上层，MSS会受到MTU的限制



