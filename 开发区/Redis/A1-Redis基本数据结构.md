## A1-Redis基本数据结构

#### 基本数据结构： String、List、Hash、Set、SortedSet、 bitMap，HyperLogLog

### String :   

动态字符串，类似于 Java 中的 ArrayList，一个字符数组；     应用：缓存;  使用 SDS 结构

####  SDS 与 C 字符串的区别：

 C 语言使用一个长度 N+1 的字符数组来表示长度为 N 的字符串，字符数组最后一个元素是 '\0’

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwjznf9x3j60nx055jrm02.jpg" alt="image-20210928191147121" width="650" height="150"/>         



**1.计数方式不同：**  C 不保存数组长度，每次都需要遍历一遍整个数组，获取字符串长度 O(N) ；  redis 自己本身就保存 长度信息
**2.避免缓冲区溢出：**执行 拼接 or 缩短字符串的操作时，可能出现 缓冲区溢出/内存泄漏 的问题
现在需要在后面拼接，但是没计算好内存，结果可能因 内存不足，被意外的修改；
SDS 结构存储 当前长度+ free未使用长度，在做拼接操作时，会判断是否可以放得下，如果长度够直接执行，如果 不够那就进行扩容
    <img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk020cnij611w0bwdgr02.jpg" alt="30466B01-C2DD-46B1-B7C0-90DD45C08A93" width="650" height="200"  />

**3.减少 修改字符串时带来的内存重分配次数：** Redis是个高速缓存数据库，如果需要对字符串进行 频繁的拼接和截断操作，在写代码时忘记了重新分配内存，就可能造成缓冲区溢出，以及内存泄露。Redis为避免 C字符串这样的缺陷，就分别采用了两种解决方案，去达到性能最大化，空间利用最大化：
***空间预分配：对SDS进行扩展操作的时候，Redis会为 SDS分配好内存，并且根据特定的公式，分配多余的 free空间，还有多余的 1byte空间（这1byte也是为了存空字符），这样就可以避免连续执行 字符串添加所带来的内存分配消耗。
*** 算法动态计算调整free值：字符串变长了，Redis还会根据算法计算出一个 free值给他备用；再继续拼接会发现，备用的 free用上了，省去这次的内存重分配

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk0n3hsdj611807ajs102.jpg" alt="DC43FF4A-EFE1-468A-AFF3-6123FF14F3E0" width="650" height="150" />

**4.惰性空间释放：** 当执行完一个字符串缩减的操作，为了预防继续添加的操作，redis并不会马上收回空间，这样来减少分配空间带来的消耗；当再次操作还没用到多余空间的时候，Redis就会收回多余的空间，防止内存的浪费。
调用删减函数，并不会马上释放掉 free空间；如果需要继续添加，则这个空间就能用上，减少内存的重分配，如果空间不需要，调用函数删掉

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk1cugrtj61120e4jsw02.jpg" alt="DB44101E-34A5-4AEF-AFCE-B7A66ACAC422" width="650" height="200" />

**5.二进制安全：** 因为 C 语言中的字符串必须符合某种编码（如 ASCII），中间出现 '\0' 可能会被判定为提前结束的字符串而识别不了；因此 C的字符串  只能保存文本数据；
Redis 保存字符串的长度，不判断空字符而是判断长度； 所以redis 可以保存 各种二进制数据，更加安全；

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk1xfew3j611a0cwgmx02.jpg" alt="FBB69EB8-5F6F-40D6-BD76-9111B9FCBF10"  width="650" height="200" />

List：双向链表，类似于 Java 中的 LinkedList，插入、删除 性能好，时间复杂度为 O(1)，但索引定位慢，查询 O(n)；   应用：消息队列；  结构：

```java
typedef struct list{
    //表 头结点
    listNode  *head;
    //表 尾节点
    listNode  *tail;
    //链表 长度
    unsigned long len;
    //节点值复制函数
    void *(*dup) (viod *ptr);
    //节点值释放函数
    void  (*free) (viod *ptr);
    //节点值对比函数
    int (*match) (void *ptr,void *key);
}list
```

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk2o47wcj60xi0eywft02.jpg" alt="C494BCEE-029D-4025-94D4-5B8B64A68BC5" width="650" height="250"/>

#### 特性：

1.无环双向链表
2.获取表头指针，表尾指针，链表节点长度的 时间复杂度均为O(1)
3.链表使用 void *指针来保存节点值，可以保存各种不同类型的值



### Hash:  

数组 + 链表， 类似于 Java 中的 HashMap ，链地址法来解决部分 哈希冲突， 2倍扩容， 初始容量 16.

#### 结构：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk36f5cej60ze0j0jsx02.jpg" alt="406435D6-0269-4F31-AAD5-4483C7B8FDC2" width="650" height="300" />

ht[0]： 用于存放真实的key-vlaue数据； ht[1]：用于扩容(rehash)
Redis中哈希算法和哈希冲突跟Java实现的差不多，它俩差异: Redis哈希冲突，链表头插法；JDK1.8后，Java哈希冲突，链表尾插法。

#### 渐进式 rehash：

Hash 扩容是比较耗时间的，需重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新数组下面，这是一个 O(n) 的操作，作为 单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 渐进式 rehash 来实现小步搬迁。

在 rehash时，保留新旧两个 hash结构，查询时先查新hash, 没有再查旧hash，并搬迁至新hash;  增加直接加到新hash;  修改先改hash, 没有改旧hash, 然后删除搬迁至新hash; 删除先删新hash, 没有再删旧hash。

**扩容条件：**当 hash表中 元素个数 == 数组.size()  扩容 原数组大小 2 倍。 如果 Redis 正在做 bgsave(持久化命令)，为减少内存，尽量不去扩容，但如果 hash 表非常满，达到一维数组长度 5 倍，这时就会 强制扩容。 
**缩容条件：**当 hash 表中  元素个数 <  数组.size() * 10% ，缩容不会考虑  是否在做 bgsave

在对哈希表进行 扩展或者收缩操作时，reash过程并不是一次性地完成的，而是 渐进式地完成的。
Redis在 rehash时采取渐进式的原因：数据量如果过大的话，一次性rehash会有庞大的计算量，这很可能导致服务器一段时间内停止服务。
Redis具体是rehash时这么干的：
1: 在字典中维持一个 索引计数器变量 rehashidx，并将设置为0，表示rehash开始。
2:在 rehash期间每次对字典进行 增加、查询、删除和更新操作时，除了执行指定命令外；还会将ht[0]中rehashidx 索引上的值 rehash到ht[1]，操作完成后 rehashidx+1。
3:字典操作不断执行，最终在某个时间点，所有的键值对完成rehash，这时将rehashidx设置为-1，表示rehash完成
4:在渐进式rehash过程中，字典会 同时使用两个哈希表ht[0]和ht[1]，所有的更新、删除、查找操作也会在两个哈希表进行。例如要查找一个键的话，服务器会优先查找ht[0]，如果不存在，再查找ht[1]，诸如此类。此外当执行新增操作时，新的键值对一律保存到ht[1]，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。



### Set ：

 键值对 无序、唯一，类似于 Java 语言中的 HashSet， 在 HashMap 的基础上对所有的 value = NULL 



### SortedSet（zset）:    

ziplist  +  跳表（ skiplist）；  应用：排行榜 ；	参考： http://blog.jobbole.com/111731/
zset 可以按照 用户指定的 排序规则对输入字段进行排序， 支持随机插入、删除
同时满足如下条件时, 使用的是 ziplist,  其他时候使用 skiplist
**1.有序集合保存的元素  数量小于128个**  
**2.有序集合保存的所有元素的 长度小于64字节**   
ziplist 为存储结构时,每个集合元素使用 两个紧挨在一起的 压缩列表结点 来保存, 第一个 节点保存元素的成员, 第二个元素保存元素的分值score 。 

#### 为什么不考虑平衡树，红黑树？

1.性能考虑： 在高并发情况下，树形结构需要执行一些 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化 只涉及局部 ；
2.实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单；

在新产生的链表上，每两个相邻的节点增加一个指针，从而产生第三层链表：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk71tl5oj60g6038jre02.jpg" alt="03F9B84C-612F-40A8-A518-1B898D67ADA4" width="750" height="150" />


skiplist  为每个节点随机出一个层数(level)，比如：一个节点随机出的层数 3，就把它链入到 第 1 层到第 3 层这三层链表中

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk7wpk4pj60u012tq6f02.jpg" alt="35A292CF-7CF8-48E7-9E0F-11775A623FBB" width="750" height="750" />

每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此 插入操作只需要 修改节点前后的指针，而不需要对多个节点都进行调整，这就降低插入操作的复杂度。 从刚才创建的这个结构中查找 23 这个不存在的数，查找路径：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk8ko5wnj60v00aeq3p02.jpg" alt="54079B05-6914-4965-B95B-FA58520C9192" width="750" height="250" />

#### 跳跃表 重要过程：

**随机层数：**
对于每一个新插入的节点，都需要调用 一个随机算法给它分配一个合理的层数；
直观上期望的目标是 50% 的概率被分配到 Level 1； 25% 的概率被分配到 Level 2； 12.5% 的概率被分配到 Level 3，以此类推...有 2^(-63) 的概率被分配到最顶层，因为这里每一层的晋升率都是 50%
默认允许 最大的层数是 32，当 Level[0] 有 264 个元素时，才能达到 32 层，所以定义 32 完全够用了
插入节点：找到当前需要插入的位置 （其中包括相同 score 时的处理）； 创建新节点，调整前后的指针指向，完成插入
节点删除: 和插入过程类似，先把 "搜索路径" 找出来，然后对于 每个层的相关节点重排一下 前向后向指针，同时更新一下最高层数 maxLevel

**节点更新:**  
当调用 ZADD 方法时，如果对应的 value 不存在，那就是插入过程，
如果这个 value 已经存在，只是调整一下 score 的值，那就需要走一个 更新流程
如果这个新的 score 值 并不会带来排序上的变化，那就不需要调整位置，直接修改元素的 score 值
如果 排序位置改变，那就需要调整位置，把这个元素 删除再插入，需要经过两次路径搜索； 需调整顺序，先删再插

**元素排名：**跳跃表是有序的， 在 skiplist 的 forward 指针上，为每一个 forward 指针都增加 span 属性，表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点 中间会跳过多少个节点
在 插入、删除操作时，都会更新 span 值的大小，所以沿着 "搜索路径"把所有经过节点的 跨度 span 值累加 就可以算出当前元素的最终 rank 值。极端情况, 跳跃表中所有 score 值都是一样，zset 的查找性能会退化为 O(n)



### BitMap:  位图   

**应用场景：**对于统计浏览某个网页的 独立访客数量 UV（Unique visitor）的业务场景，考虑使用 BitMap、 布隆过滤器（缓存穿透）  

Redis 位图是一个 二进制位组成的数组，数组的每个单元只能存储 0和1。 将数组中的每个 二进制位与用户 ID 一一对应， 使用位图去记录每个用户当日是否访问，存储的 1的个数就是UV数量。以 当天的日期加固定的前缀作为key，建立一个Bitmap，每一位二进制的 offset做为一个用户 ID的标识，当今天用户访问时就将Bitmap中标识此用户的二进制（value）从0置为1。最后统计所有bitmap 中 1 的个数，即为独立访客数量。


<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwk9dz2toj60dw0bgjrl02.jpg" alt="F49C49F5-90EC-4448-870F-23D9E3A0A472" width="350" height="250" />



### HyperLogLog： 

基数统计 通常是用来 统计一个集合中不重复的元素个数 ；某个网页的 独立访客数量 UV（Unique visitor）的业务场景
Bitmap 已经节约了内存，但如果页面访问量非常大（例如用户规模达到1亿），那么用于统计单个页面的UV内存占用需要 100000000/8/1024/1024 ≈ 12M；若分别统计多个页面，则内存占用会线性增加。如果只需要 每天的UV大致统计数量，使用HyperLogLog 比较合适。
HyperLogLog 是用来做 基数估计的算法，HyperLogLog 用12K字节的内存占用，可以计算接近 264 个不同元素的基数（UV）

2.比特串的基数估计
在UV统计中需要统计一组集合中 不重复元素的个数。利用哈希算法将集合中的数据转换成 0和1构成的二进制数串，那么一个二进制串可以类比为一次抛硬币实验，1是抛到正面，0是反面。
使用 MurmurHash2 算法来计算 集合数据的哈希值，该算法有很好的均匀性，即使输入集合数据按规律排列，哈希之后仍能保证数据随机分布，因此可以保证每 bit出现 0或1的概率均为1/2，Redis中采用的是MurmurHash2固定64比特版本，另外该算法的计算速度也较快。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwka6pez0j60v80hwdid02.jpg" alt="AC03EB09-D3C4-4316-80D1-D5A6723A1C4C" width="650" height="350" />

HLL算法思想的核心就在于通过 保留少量的比特信息，来 估计或观察消息流。二进制串中从低位开始第一个 1出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数k，那么基于上面的结论，可以 通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，通过第一个1出现位置的最大值  kmax来预估总共有多少个不同数字

#### 分桶平均 

如果直接应用上面的HLL方法进行基数估计会由于偶然性带来较大的误差，因此 HLL算法采用分桶平均的方法来消减偶然性的误差、提高估计的准确度。
1.先把数据 分成若干个分组（桶bucket），估计每个分组的基数
2.然后用所有 分组基数的平均数来估计总的基数。
Redis 中桶的个数是16384，对于每个哈希值（64bit），14 位作为 桶编号用来定位数据分布的桶位置，剩余的50bit 即伯努利过程，每个桶对应 6 bit大小，记录kmax。
举例说明，若 UV值通过Hash 算法得到比特串:  10110000 00000000 01101100 00000100 00101001 11000000 00 000100 00011101 
后面 14位确定桶编号，即bucket=1053; 前面的50 bit 伯努利过程，该例中 kmax= 9，那么UV基数估计为29  
多个桶用平均数计算，HLL采用的是 调和平均方法，然后再基于 因子修正公式计算得出，调和平均较比 几何平均有更高的精度
Redis中规定 分桶个数16384，每个桶的kmax用 6bit空间来存放，6*16384/8 字节，再加上结构头等数据，加起来一共12304个字节；用12K字节的内存占用，即可 计算接近 264 个不同元素的基数。这和基数越大占用内存越大的其它计算基数的方式形成鲜明对比。
但Redis对应内存的节约还不止于此，12K字节内存是 encoding=HLL_DENSE(密集)模式下的内存占用；
对于基数值比较少，大多数桶的计数值kmax为0的情况，Redis采用HLL_SPARSE稀疏模式的存储，稀疏存储的空间占用远小于12K字节。对密集存储和稀疏存储方式，本文做简单介绍：
密集存储的结构很简单，就是连续的 16384个6比特连起来的位图。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwkb4wfj2j610s04kmxq02.jpg" alt="6715C6C3-8585-4629-BD40-59DE35B1111B" width="650" height="100" />

稀疏存储 针对的就是很多的桶计数值为 0的情况，因此会有大量连续0的情况出现

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwkbpk601j6156050gmo02.jpg" alt="23A5FB80-92CF-4E8B-8236-40C6F3C4ABAA" width="650" height="100" />

#### 使用 set 集合问题：

1. 存储空间巨大： 如果数量庞大，则需要用来存储的 set 集合就会非常大，去重功能将耗费较高的时间复杂度 ，影响性能
2. 统计复杂： 每个场景都需要一个set，对于多个 set 集合，如果要聚合统计一下，也是一个复杂的事情







#### Redis 过期策略： 定期删除+ 惰性删除 

定期删除：默认100ms 就随机抽一些 设置了过期时间的key，去检查是否过期，过期了就删
如果一直没随机到很多key，里面不就存在大量的无效key了？ 
惰性删除：不主动删，等你来查询我，看看过期没，过期就删了

定期没删，也没查询，那可咋整？

#### 内存淘汰策略：

1.noeviction:  永不删除
2.allkeys-random:  无过期时间的数据，随机删除一部分
3.allkeys-lru: 无过期时间的数据，删除 最近最少使用的（LRU）
4.volatile-random:  设置过期时间的数据，随机删除一部分
5.volatile-lru: 有过期时间的数据，删除最近最少使用的（LRU）
6.volatile-ttl: 有过期时间的数据，删除 剩余时间最短的（TTL）

#### 缓存穿透：

缓存和数据库 中都没有的数据，而用户不断发起请求，导致请求不走缓存，直接访问到数据库，数据库压力过大
通常是 请求参数非法导致，(例如 id=-1)

#### 解决：

1.接口层 增加校验，比如 用户鉴权校验，参数做校验
2.在缓存中取不到，数据库中也没有取到，此时将对应Key的 Value 改写：{ null、位置错误、稍后重试 }，参照具体的场景
3.布隆过滤器（Bloom Filter）利用bitMap结构和hash算法，判断出这个Key是否在数据库中存在，不存在 return，存在就去查 DB刷新KV 再return



**缓存击穿：**一个热点 Key，扛着高并发，当这个Key在失效瞬间，持续的高并发击穿缓存，直接请求到数据库
解决：
1.设置 热点数据永远不过期
2.加上互斥锁，保证 同一进程中对同一数据，不会并发请求到DB



**缓存雪崩：**同一时间多个热点 Key值， 大面积失效，导致大量请求访问到DB
解决：
1.把每个 Key的失效时间都加个随机值，保证 数据不会在同一时间大面积失效
2.设置 热点数据永远不过期 
3.将 多个热点数据 均匀分布在不同的Redis库中 
4.使用主从、集群模型，提高缓存服务的高可用
缓存雪崩需要做 熔断等策略

* 事前： Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃
* 事中： 本地 ehcache 缓存 + Hystrix 限流+降级，避免MySQL被打死
* 事后： Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据

