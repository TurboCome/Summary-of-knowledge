## A3-Redis 优化

#### 布隆过滤器： 应用场景：缓存穿透，海量数据去重 

​		K 个哈希函数，每个 字符串跟 k 个 bit对应，降低冲突概率
当一个元素被加入集合时，通过  K个散列函数 将这个元素映射成一个 位数组中的K个点，把它们置为 1,  检索时只要看这些点 是不是为 1 就知道集合中有没有它了。如果 这些点有任何一个 0，则被检元素一定不在；  如果都是1，则被检元素很可能在
**Bloom Filter 和单哈希函数 Bit-Map不同：**Bloom Filter使用了 k个哈希函数，每个 字符串跟 k个bit对应。降低冲突概率

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwks943stj60oy0d8dh802.jpg" alt="DB32F606-7EE5-46FC-9E99-3B5438DC21F1" width="650" height="300"/>

#### 存在的问题：

**存在误判：**hash之后得到的  k个位置上值都是1，但可能此值不存在； 
**解决：**可以通过建立一个 白名单来存储可能会误判的元素
删除困难： 一个放入容器的元素映射到 bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断；   
解决： 可以采用Counting Bloom Filter



#### 分布式锁： 常规锁只能适用于单机，对于 分布式架构无法保证

避免不同节点重复相同的工作： 比如用户执行某个操作有可能不同节点会发送多封邮件；
避免破坏数据的正确性：如果两个节点在同一条数据上同时进行操作，可能会造成数据错误或不一致的情况出现；

#### Redis 分布式锁的问题： 锁超时 

有两台平行的服务 A B，其中 A 服务在 获取锁之后 由于某种原因突然 挂了，那么 B 服务就永远无法获取到锁； 需要额外设置一个超时时间，来保证服务的可用性。如果 加锁，释放锁 之间的逻辑执行得太长，以至于 超出了锁的超时限制，也会出现问题。
因为这时第一个线程持有锁过期了，而临界区逻辑还没执行完，与此同时第二个线程就提前拥有了这把锁，导致临界区的代码不能得到严格的串行执行。为避免这个问题，Redis 分布式锁 不要用于较长时间的任务。

**解决：标记版本号**  将锁 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key， 确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期而被服务器自动释放的，但匹配  value 和 删除 key 在 Redis 中并不是一个原子性的操作，需要使用像 Lua 脚本来处理，因为 Lua 脚本可以 保证多个指令的原子性执行



#### 分布式锁：setnx 是 SET if Not exists

设置过期时间：  EXPIRE name  5       # 5s 后过期
EXPIRE 命令依赖于 SETNX 的执行结果，而事务中没有 if-else 的分支逻辑，如果 SETNX 没有抢到锁，EXPIRE 就不应该执行。
加入 SET 指令扩展参数，使 SETNX 和 EXPIRE 指令一起执行： SET key value [EX seconds | PX milliseconds] [NX | XX] [KEEPTTL]
设置一个过期时间，就算线程 1挂了，也会在失效时间到了，自动释放
计数： 使用 INCR 命令进行 原子性 的自增操作，多个 客户端对同一个 key 进行操作，也决不会导致竞争的情况

Setnx 加锁， expire 过期时间； 不是原子性操作； 
Redis:: set( "my:lock",   $token,  "nx", "ex", 10);
直接使用 set进行锁，参数配置，让 加锁+过期时间 成原子操作；传统的 del 解锁方式，存在问题； 如果  expire time 释放锁后， 其他线程重新获取，直接 del 解锁，会删除别人建立的锁了。通过 lua脚本（保证一系列操作的原子性），先进行 get，再进行 del； 外加 token 字段，一个随机数，当 lock的时候，往redis的 my:lock中存的是这个token，unlock的时候，先 get一下lock中的token，如果 和要删除的 token是一致的，说明这个锁是之前我 set的，否则说明这个锁已经过期，是别人set的，就不应该对它进行任何操作。

#### 场景题：假如 Redis里面有1亿个 key，有10w key 是以某个固定前缀开头，如何全部找出？  

使用 keys 指令可以扫出 指定模式的 key列表；如果 redis正在给 线上的业务提供服务，那使用 keys指令会有什么问题？
Redis单线程的，keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。
可以使用 scan指令，无阻塞的提取出指定模式的key列表，但会有一定的重复概率，需要在客户端做一次去重，整体所花费的时间会比直接用keys指令长。

分布式场景下，多个微服务间协同调用，调用链使用 UUID 唯一



#### redis常见性能问题和解决方案：

1.Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master最好不要写内存快照。
2.Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响 Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化, 如果数据比较关键，某个 Slave开启AOF备份数据，策略为每秒同步一次。
3.Master 调用bgrewrite AOF 重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
4.Redis主从复制的性能问题，为主从复制速度和连接的稳定性，Slave和 Master最好在同一个局域网内。

#### Redis 事务特征：

1.在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端请求提供任何服务，从而保证s事务中的所有命令被原子的执行。
2.和关系型数据库中的事务相比，在 Redis事务中，如果 某一条命令执行失败，其后的命令仍然会被继续执行。
3.通过 multi 命令开启一个事务，在该语句之后执行的命令都将被视为事务之内的操作，最后通过执行 exec/discard  命令来提交/ 回滚 该事务内的所有操作。 这两个Redis命令可被视为等同于关系型数据库中的 commit/rollback 语句。
4.在事务开启之前，如果 客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。如果网络中断事件是发生在客户端执行exec 命令之后，那么该事务中的所有命令都会被服务器执行。
5.当使用 Append-Only模式时，Redis会通过调用系统函数write 将该事务内的所有写操作在本次调用中全部写入磁盘。如果在写入过程中出现系统崩溃，如电源故障导致宕机，此时也许只有部分数据被写入到磁盘，而另一部分数据却已经丢失。Redis服务器会在重启时执行一系列必要的一致性检测，一旦发现类似问题，会立即退出并给出相应的错误提示。 此时需要充分利用Redis 工具包中提供的 redis-check-aof工具来定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复后就可以再次重新启动 Redis服务器了。



#### Redis做异步队列：

使用 list结构作为队列，rpush生产消息， lpop消费消息
当lpop没有消息的时候，要适当sleep一会再重试。不使用 sleep: list还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。

使用 pub/sub主题订阅者模式，可以实现 1:N 的消息队列。
pub/sub缺点： 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等

#### 使用Redis 实现可靠的消息队列 ack 机制？

消费者用 rpop 取出元素，若消费者在 取出元素之后崩溃了，此时消息 已被取出且没有正确处理，会造成该消息的丢失
队列的备份：消费者程序在 从主消息队列中取出消息后，再将其插入到备份队列中，直到消费者程序完成正常的处理逻辑后再将该消息从备份队列中删除。
当备份队列中消息过期时，重新将其 再放回到主消息队列中，以便其它的消费者程序继续处理。RPOPLPUSH命令执行过程示意图如下：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1guwktpi57yj60yc0kyq4o02.jpg" alt="7D32B33D-052D-4C35-AB1A-9F995B4E0833" width="650" height="350" />

#### Redis 如何实现延时队列？

使用 sortedset，拿时间戳作为 score，消息内容作为 key调用 zadd来生产消息，消费者用 zrangebyscore指令获取N秒之前的数据轮询进行处理。

